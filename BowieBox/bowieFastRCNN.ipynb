{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66162b8-4b11-4924-a5e0-d34a19410e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be35c45-9101-45ef-b6b4-e58cc9cd37d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ffe5c42-3555-48dd-b698-76d78bf90f77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72215bbd-2d2a-49cf-bd5c-d7064f37ea1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def smooth_l1_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the Smooth L1 loss between the true and predicted bounding box coordinates.\n",
    "\n",
    "    :param y_true: Ground truth bounding box coordinates (tensor of shape (batch_size, num_boxes, 4))\n",
    "    :param y_pred: Predicted bounding box coordinates (tensor of shape (batch_size, num_boxes, 4))\n",
    "    :return: Smooth L1 loss (scalar value)\n",
    "    \"\"\"\n",
    "    # Compute the absolute difference between true and predicted coordinates\n",
    "    abs_diff = tf.abs(y_true - y_pred)\n",
    "\n",
    "    # Determine where the absolute difference is less than or equal to 1\n",
    "    mask = tf.cast(tf.less_equal(abs_diff, 1.0), dtype=tf.float32)\n",
    "\n",
    "    # Calculate the smooth L1 loss\n",
    "    l1_loss = mask * (0.5 * abs_diff ** 2) + (1 - mask) * (abs_diff - 0.5)\n",
    "\n",
    "    # Return the mean loss over all bounding boxes\n",
    "    return tf.reduce_mean(l1_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb32ba34-899a-447a-9d0c-bf17d7e16f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Assuming 'base_model' is the variable for your base VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add the classification output\n",
    "classification_output = Dense(1, activation='sigmoid', name='classification_output')(x)\n",
    "\n",
    "# Add the bounding box regression output\n",
    "bbox_regression_output = Dense(4, activation='linear', name='bbox_regression_output')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=[classification_output, bbox_regression_output])\n",
    "\n",
    "# Compile the model with multiple outputs and losses\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "losses = {\n",
    "    \"classification_output\": \"binary_crossentropy\",\n",
    "    \"bbox_regression_output\": \"mean_squared_error\",\n",
    "}\n",
    "model.compile(loss=losses, optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a11a76c-a91d-4a76-8a30-39749ff42742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def load_data(aug_data_dir):\n",
    "    image_files = []\n",
    "    annotations = []\n",
    "    \n",
    "    label_dir = os.path.join(aug_data_dir, 'Labels').replace(\"\\\\\", \"/\")\n",
    "    image_dir = os.path.join(aug_data_dir, 'Images').replace(\"\\\\\", \"/\")\n",
    "    num = 0\n",
    "    for file in os.listdir(label_dir):\n",
    "        if file.endswith('.json'):\n",
    "            if str(file) == \"4A505756-D16F-4D0C-A6B4-663CDE06AB5B.77.json\":\n",
    "                print(\"FOUND\")\n",
    "                continue\n",
    "            json_file = os.path.join(label_dir, file)\n",
    "\n",
    "            # Load data\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Extract image path and annotations\n",
    "            image_file_name = f\"{data['image'][:-4]}.{num}.jpg\"\n",
    "            image_file = os.path.join(image_dir, image_file_name).replace(\"\\\\\", \"/\").replace(\"..\", \".\")\n",
    "            num+=1\n",
    "            if num == 80:\n",
    "                num = 0\n",
    "            image_files.append(image_file)\n",
    "\n",
    "            image_annotations = []\n",
    "\n",
    "            bbox_data = data['bbox']\n",
    "            label = data['class']\n",
    "            xmin = bbox_data[0]\n",
    "            ymin = bbox_data[1]\n",
    "            xmax = bbox_data[2]\n",
    "            ymax = bbox_data[3]\n",
    "            bbox = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "            annotation = {\n",
    "                'class': label,\n",
    "                'bbox': bbox\n",
    "            }\n",
    "            image_annotations.append(annotation)\n",
    "\n",
    "            annotations.append(image_annotations)\n",
    "\n",
    "    return image_files, annotations\n",
    "\n",
    "aug_data_dir = 'aug_data'\n",
    "image_files, annotations = load_data(aug_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f477b2f0-4623-4eb9-8e78-d7fff0e853cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5679, 5679)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_files), len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2e633d0-cdd4-4b4e-b311-4ebd49f910bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5679, 5679)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(image_files), len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeecd19b-af9d-4162-b1aa-4a05db124c49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0   4]\n",
      "  [  0   0   5]\n",
      "  [  0   0   6]\n",
      "  ...\n",
      "  [  0   0  10]\n",
      "  [  0   1   9]\n",
      "  [  0   1   9]]\n",
      "\n",
      " [[  0   0   4]\n",
      "  [  0   0   5]\n",
      "  [  0   0   6]\n",
      "  ...\n",
      "  [  1   2  12]\n",
      "  [  0   0  10]\n",
      "  [  0   1   9]]\n",
      "\n",
      " [[  0   0   4]\n",
      "  [  0   0   4]\n",
      "  [  0   1   5]\n",
      "  ...\n",
      "  [  2   3  13]\n",
      "  [  0   1  11]\n",
      "  [  0   1  11]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 95 117 142]\n",
      "  [ 97 119 144]\n",
      "  [ 98 120 145]\n",
      "  ...\n",
      "  [103 126 148]\n",
      "  [106 127 149]\n",
      "  [106 127 149]]\n",
      "\n",
      " [[ 96 120 142]\n",
      "  [ 96 120 142]\n",
      "  [ 96 120 142]\n",
      "  ...\n",
      "  [102 125 147]\n",
      "  [105 125 150]\n",
      "  [105 125 150]]\n",
      "\n",
      " [[ 95 120 140]\n",
      "  [ 96 121 141]\n",
      "  [ 96 120 142]\n",
      "  ...\n",
      "  [102 125 147]\n",
      "  [105 125 150]\n",
      "  [105 125 150]]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(image_files[0])\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56647bd3-4376-480e-9a75-b9ea3e6a2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def preprocess_data(image_files, annotations):\n",
    "    images = []\n",
    "    class_labels = []\n",
    "    bbox_labels = []\n",
    "\n",
    "    for image_file, annotation in zip(image_files, annotations):\n",
    "        if image_file == \"aug_data/Images/4A505756-D16F-4D0C-A6B4-663CDE06AB5B.77.jpg\":\n",
    "            continue\n",
    "        img = cv2.imread(image_file)\n",
    "        \n",
    "        # Check if the image is loaded correctly\n",
    "        if img is None:\n",
    "            print(f\"Error loading image: {image_file}\")\n",
    "            continue\n",
    "\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img_to_array(img)\n",
    "        img = preprocess_input(img)\n",
    "\n",
    "        for obj in annotation:\n",
    "            label = obj['class']\n",
    "            bbox = obj['bbox']\n",
    "            class_labels.append(label)\n",
    "            bbox_labels.append(bbox)\n",
    "\n",
    "        images.append(img)\n",
    "\n",
    "    return np.array(images), np.array(class_labels), np.array(bbox_labels)\n",
    "\n",
    "X, y_class, y_bbox = preprocess_data(image_files, annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "513063b8-f8e5-4a57-ad31-119e3c5f9122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5678, 5678, 5678)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y_class), len(y_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b379d59-5f3d-4f37-b729-cffa1099f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_class_train, y_class_test, y_bbox_train, y_bbox_test = train_test_split(X, y_class, y_bbox, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3c071fc-fb99-4fee-9aa1-079b1edca3f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassification_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_class_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbbox_regression_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bbox_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassification_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_class_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbbox_regression_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bbox_test\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bowieGPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bowieGPU\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "hist = model.fit(\n",
    "    X_train,\n",
    "    {\"classification_output\": y_class_train, \"bbox_regression_output\": y_bbox_train},\n",
    "    validation_data=(X_test, {\"classification_output\": y_class_test, \"bbox_regression_output\": y_bbox_test}),\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f242e1d9-cd65-4a6c-bc20-3a38449659d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "[array([[0.99916804]], dtype=float32), array([[0.01691841, 0.26591307, 0.795064  , 0.7683325 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load and preprocess the input image\n",
    "input_image_path = 'aug_data/Images/4A505756-D16F-4D0C-A6B4-663CDE06AB5B.33.jpg'\n",
    "input_image = cv2.imread(input_image_path)\n",
    "original_image = input_image.copy()\n",
    "\n",
    "input_image = cv2.resize(input_image, (224, 224))\n",
    "input_image = img_to_array(input_image)\n",
    "input_image = preprocess_input(input_image)\n",
    "input_image = np.expand_dims(input_image, axis=0)\n",
    "\n",
    "# 2. Make a prediction using the model\n",
    "prediction = model.predict(input_image)\n",
    "print(prediction)\n",
    "predicted_class = np.argmax(prediction[0])\n",
    "predicted_bbox = prediction[1][0]\n",
    "\n",
    "# 3. Convert the predicted bounding box coordinates to their original scale\n",
    "image_height, image_width, _ = original_image.shape\n",
    "xmin = int(predicted_bbox[0] * image_width)\n",
    "ymin = int(predicted_bbox[1] * image_height)\n",
    "xmax = int(predicted_bbox[2] * image_width)\n",
    "ymax = int(predicted_bbox[3] * image_height)\n",
    "\n",
    "# 4. Draw the bounding box on the input image\n",
    "color = (0, 255, 0)  # Green color for the bounding box\n",
    "thickness = 2\n",
    "cv2.rectangle(original_image, (xmin, ymin), (xmax, ymax), color, thickness)\n",
    "\n",
    "# 5. Display the image with the bounding box\n",
    "cv2.imshow('Predicted Bounding Box', original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a334933f-710f-469a-807a-08c6b44af45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bowieGPU",
   "language": "python",
   "name": "bowiegpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
